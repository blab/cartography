
from snakemake.utils import min_version
min_version("6.0")

from snakemake.utils import Paramspace
import pandas as pd

METHOD_PARAMETERS = Paramspace(
    pd.read_csv(
        "config/method_parameters.tsv",
        sep="\t"
    )
)

wildcard_constraints:
    segment="(ha|na|ma)",
    ha_concatenated="(ha|na|ma|concatenated|ma_concatenated)",
    method="(mds|t-sne|umap)"

EMBEDDING_METHODS = [
    "mds",
    "t-sne",
    "umap"
]

SEGMENTS = [
    "ha",
    "na",
    "ma"
]

HA_CONCATENATED = [
    "ha",
    "na",
    "ma",
    "concatenated",
    "ma_concatenated"
]
HA_CONCAT = [
    "concatenated",
    "ma_concatenated",
    "ha"
]


rule all:
    input:
        "results/ncbi-h3n2-ha.fasta",
        expand("results/deduplicated_sequences_{segment}.fasta", segment=SEGMENTS),
        "results/paired_ha.fasta",
        expand("results/aligned_{segment}.fasta", segment=SEGMENTS),
        expand("results/filtered_{segment}.fasta", segment=SEGMENTS),
        expand("results/metadata_{segment}.tsv", segment=SEGMENTS),
        "results/aligned_ma_concatenated.fasta",
        "results/aligned_concatenated.fasta",
        expand("results/tree_{segment}.nwk", segment=SEGMENTS),
        expand("results/cartography_flu-seasonal-h3n2-{segment}-2016-2018-reassort.json", segment=SEGMENTS),
        expand("results/table_{segment}.tsv", segment=SEGMENTS),
        expand("results/embed_mds_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED),
        expand("results/embed_t-sne_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED),
        expand("results/embed_umap_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED),
        expand("results/gridsearch_{ha_concatenated}.tsv", ha_concatenated=HA_CONCATENATED),
        HANAMAFullChartBrushableMDSHTML = "../docs/HANAMAFullChartBrushableMDS.html",
        HANAMAFullChartBrushableMDSPNG = "../docs/HANAMAFullChartBrushableMDS.png",
        HANAMAFullChartBrushableTSNEHTML = "../docs/HANAMAFullChartBrushableTSNE.html",
        HANAMAFullChartBrushableTSNEPNG = "../docs/HANAMAFullChartBrushableTSNE.png"
rule files:
    params:
        input_fasta = "data/ncbi-h3n2-ha-na.fa",
        dropped_strains = "config/exclude.txt",
        reference = "config/reference_h3n2_ha.gb",
        auspice_config = "config/auspice_config.json",
        clades = "config/clades_h3n2_ha.tsv"

files = rules.files.params

rule split_ma:
    message:
        """
        Split the ha and na file into separate files
        """
    input:
        sequences =  "data/ncbi-h3n2-ha-na-ma.fa"
    output:
        sequences_ha = "results/ncbi-h3n2-ha.fasta",
        sequences_na = "results/ncbi-h3n2-na.fasta",
        sequences_ma = "results/ncbi-h3n2-ma.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/split_fasta_mp.py \
            --sequence {input.sequences} \
            --output_fastas {output.sequences_ha} {output.sequences_na} {output.sequences_ma}\
        """

rule parse:
    message: "Parsing fasta into sequences and metadata"
    input:
        sequences = "results/ncbi-h3n2-{segment}.fasta"
    output:
        sequences = "results/sequences_{segment}.fasta",
        metadata = "results/metadata_{segment}.tsv"
    params:
        fasta_fields = "strain date accession country region segment_name"
    conda: "../cartography.yml"
    shell:
        """
        augur parse \
            --sequences {input.sequences} \
            --output-sequences {output.sequences} \
            --output-metadata {output.metadata} \
            --fields {params.fasta_fields}
        """

rule deduplicate_sequences:
    message:
        """
        Deduplicating sequences
        """
    input:
        sequences = "results/sequences_{segment}.fasta"
    output:
        sequences = "results/deduplicated_sequences_{segment}.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/deduplicate_sequences.py \
            --sequences {input.sequences} \
            --output {output.sequences}
        """

rule filter:
    message:
        """
        Filtering to
          - excluding strains in {input.exclude}
        """
    input:
        sequences = "results/deduplicated_sequences_{segment}.fasta",
        metadata = "results/metadata_{segment}.tsv",
        exclude = files.dropped_strains
    output:
        sequences = "results/filtered_{segment}.fasta"
    conda: "../cartography.yml"
    shell:
        """
        augur filter \
            --sequences {input.sequences} \
            --metadata {input.metadata} \
            --exclude {input.exclude} \
            --output {output.sequences}
        """

rule pair_ha_strains:
    message: "making ha strains same as na strains"
    input:
        sequences_ha = "results/filtered_ha.fasta",
        sequences_na = "results/filtered_na.fasta",
        sequences_ma = "results/filtered_ma.fasta"
    output:
        output_ha = "results/paired_ha.fasta",
        output_na = "results/paired_na.fasta",
        output_ma = "results/paired_ma.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/filter_ha_ma.py \
            --sequence {input.sequences_ha} {input.sequences_na} {input.sequences_ma}\
            --output_fasta {output.output_ha} {output.output_na} {output.output_ma}
        """

rule align:
    message:
        """
        Aligning sequences
          - filling gaps with N
        """
    input:
        sequences = "results/paired_{segment}.fasta",
        reference = "config/reference_h3n2_{segment}.gb"
    output:
        alignment = "results/aligned_{segment}.fasta"
    conda: "../cartography.yml"
    threads: 4
    shell:
        """
        augur align \
            --sequences {input.sequences} \
            --reference-sequence {input.reference} \
            --output {output.alignment} \
            --fill-gaps \
            --remove-reference \
            --nthreads {threads}
        """

rule concat:
    message:
        """putting the na strains with the ha strains"""
    input:
        sequence_ha = "results/aligned_ha.fasta",
        sequence_na = "results/aligned_na.fasta",
    output:
        fasta = "results/aligned_concatenated.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/concat_sequences.py \
            --sequences {input.sequence_ha} {input.sequence_na}\
            --output {output.fasta} \
        """

rule concat_ma:
    message:
        """putting the na strains with the ha strains"""
    input:
        sequence_ha = "results/aligned_ha.fasta",
        sequence_na = "results/aligned_na.fasta",
        sequence_ma = "results/aligned_ma.fasta"
    output:
        fasta = "results/aligned_ma_concatenated.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/concat_seq_mp.py \
            --sequences {input.sequence_ha} {input.sequence_na} {input.sequence_ma} \
            --output {output.fasta} \
        """

rule tree:
    message: "Building tree"
    input:
        alignment = "results/aligned_{segment}.fasta"
    output:
        tree = "results/tree_raw_{segment}.nwk"
    conda: "../cartography.yml"
    threads: 4
    shell:
        """
        augur tree \
            --alignment {input.alignment} \
            --output {output.tree} \
            --nthreads {threads}
        """

rule refine:
    message:
        """
        Refining tree
          - estimate timetree
          - use {params.coalescent} coalescent timescale
          - estimate {params.date_inference} node dates
          - filter tips more than {params.clock_filter_iqd} IQDs from clock expectation
        """
    input:
        tree = rules.tree.output.tree,
        alignment = "results/aligned_{segment}.fasta",
        metadata = "results/metadata_{segment}.tsv",
    output:
        tree = "results/tree_{segment}.nwk",
        node_data = "results/_{segment}.json"
    params:
        coalescent = "opt",
        date_inference = "marginal",
        clock_filter_iqd = 4,
        clock_rate = 0.00382,
        clock_std_dev = 0.000764
    conda: "../cartography.yml"
    shell:
        """
        augur refine \
            --tree {input.tree} \
            --alignment {input.alignment} \
            --metadata {input.metadata} \
            --output-tree {output.tree} \
            --output-node-data {output.node_data} \
            --timetree \
            --coalescent {params.coalescent} \
            --date-confidence \
            --date-inference {params.date_inference} \
            --clock-filter-iqd {params.clock_filter_iqd} \
            --clock-rate {params.clock_rate} \
            --clock-std-dev {params.clock_std_dev}
        """

rule ancestral:
    message: "Reconstructing ancestral sequences and mutations"
    input:
        tree = rules.refine.output.tree,
        alignment = "results/aligned_{segment}.fasta"
    output:
        node_data = "results/nt_muts_{segment}.json"
    params:
        inference = "joint"
    conda: "../cartography.yml"
    shell:
        """
        augur ancestral \
            --tree {input.tree} \
            --alignment {input.alignment} \
            --output-node-data {output.node_data} \
            --inference {params.inference}
        """

rule translate:
    message: "Translating amino acid sequences"
    input:
        tree = rules.refine.output.tree,
        node_data = rules.ancestral.output.node_data,
        reference = files.reference
    output:
        node_data = "results/aa_muts_{segment}.json"
    conda: "../cartography.yml"
    shell:
        """
        augur translate \
            --tree {input.tree} \
            --ancestral-sequences {input.node_data} \
            --reference-sequence {input.reference} \
            --output {output.node_data}
        """

rule clades:
    message: " Labeling clades as specified in config/clades.tsv"
    input:
        tree = rules.refine.output.tree,
        aa_muts = rules.translate.output.node_data,
        nuc_muts = rules.ancestral.output.node_data,
        clades = files.clades
    output:
        clade_data = "results/clades_{segment}.json"
    conda: "../cartography.yml"
    shell:
        """
        augur clades --tree {input.tree} \
            --mutations {input.nuc_muts} {input.aa_muts} \
            --clades {input.clades} \
            --output {output.clade_data}
        """

rule traits:
    message: "Inferring ancestral traits for {params.columns!s}"
    input:
        tree = rules.refine.output.tree,
        metadata = "results/metadata_{segment}.tsv",
    output:
        node_data = "results/traits_{segment}.json",
    params:
        columns = "region country"
    conda: "../cartography.yml"
    shell:
        """
        augur traits \
            --tree {input.tree} \
            --metadata {input.metadata} \
            --output {output.node_data} \
            --columns {params.columns} \
            --confidence
        """

rule export:
    message: "Exporting data files for for auspice"
    input:
        tree = rules.refine.output.tree,
        metadata = "results/metadata_{segment}.tsv",
        branch_lengths = rules.refine.output.node_data,
        traits = rules.traits.output.node_data,
        nt_muts = rules.ancestral.output.node_data,
        aa_muts = rules.translate.output.node_data,
        embeddings = expand("results/embed_{embedding}_ha.json", embedding=EMBEDDING_METHODS),
        embeddings_concat = expand("results/embed_{embedding}_ma_concatenated_renamed.json", embedding=EMBEDDING_METHODS),
        auspice_config = files.auspice_config,
        colors = "config/colors.tsv",
        clades = "results/clades_ha.json"
    output:
        auspice_tree = "results/cartography_flu-seasonal-h3n2-{segment}-2016-2018-reassort.json"
    conda: "../cartography.yml"
    shell:
        """
        augur export v2 \
            --tree {input.tree} \
            --metadata {input.metadata} \
            --node-data {input.branch_lengths} {input.traits} {input.clades} {input.nt_muts} {input.aa_muts} {input.embeddings} {input.embeddings_concat} \
            --auspice-config {input.auspice_config} \
            --colors {input.colors} \
            --output {output.auspice_tree}
        """

def _get_embedding_columns_by_wildcards_mds_umap(wildcards):
    method = wildcards.mds_umap
    if method in ("mds"):
        return f"{method}1 {method}2"
    else:
        return f"{method}_x {method}_y"

rule tree_to_table:
    message: "creating a table of node data values from the tree attributes"
    input:
        tree = rules.export.output.auspice_tree
    output:
        table = "results/table_{segment}.tsv"
    params:
        attributes = "num_date mds1 mds2 tsne_x tsne_y umap_x umap_y clade_membership mds_label umap_label t-sne_label"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/auspice_tree_to_table.py \
            {input.tree} \
            {output.table} \
            --attributes {params.attributes}
        """

rule create_distance_matrix:
    message: "creating the distance matrix to be used in the rest of the analysis"
    input:
        alignment = "results/aligned_{ha_concatenated}.fasta"
    output:
        output = "results/distance_matrix_{ha_concatenated}.csv"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/hamming_distance_from_fasta.py \
            --alignment {input.alignment} \
            --output {output.output}
        """

rule embed_tsne:
    message: "Creating the embedding (dataframe, node JSON) for t-SNE"
    input:
        distance_matrix = rules.create_distance_matrix.output.output,
        cluster = "results/t-sne_parameters_{ha_concatenated}.csv",
    output:
        node_data = "results/embed_t-sne_{ha_concatenated}.json",
        dataframe = "results/embed_t-sne_{ha_concatenated}.csv",
        figure = "results/embed_t-sne_{ha_concatenated}.pdf"
    params:
        perplexity = 25.95,
        learning_rate = 200
    conda: "../cartography.yml"
    shell:
        """
        embed \
            --distance-matrix {input.distance_matrix} \
            --cluster-data {input.cluster} \
            --random-seed 314159 \
            --output-node-data {output.node_data} \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            t-sne \
            --perplexity {params.perplexity} \
            --learning-rate {params.learning_rate}
        """

rule embed_umap:
    message: "Creating the embedding (dataframe, node JSON) for UMAP"
    input:
        distance_matrix = rules.create_distance_matrix.output.output,
        cluster = "results/umap_parameters_{ha_concatenated}.csv",
    output:
        node_data = "results/embed_umap_{ha_concatenated}.json",
        dataframe = "results/embed_umap_{ha_concatenated}.csv",
        figure = "results/embed_umap_{ha_concatenated}.pdf"
    params:
        nearest_neighbors = 200,
        min_dist = .5
    conda: "../cartography.yml"
    shell:
        """
        embed \
            --distance-matrix {input.distance_matrix} \
            --cluster-data {input.cluster} \
            --random-seed 314159 \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            umap \
            --nearest-neighbors {params.nearest_neighbors} \
            --min-dist {params.min_dist}
        """

rule embed_mds:
    message: "Creating the embedding (dataframe, node JSON) for MDS"
    input:
        distance_matrix = rules.create_distance_matrix.output.output,
        cluster = "results/mds_parameters_{ha_concatenated}.csv",
    output:
        node_data = "results/embed_mds_{ha_concatenated}.json",
        dataframe = "results/embed_mds_{ha_concatenated}.csv",
        figure = "results/embed_mds_{ha_concatenated}.pdf"
    params:
        components = 2
    conda: "../cartography.yml"
    shell:
        """
        embed \
            --distance-matrix {input.distance_matrix} \
            --cluster-data {input.cluster} \
            --random-seed 314159 \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            mds \
            --components {params.components} \
        """

rule create_node_output:
    message: "creates node output that is used by augur to create the phylogenies"
    input: 
        dataframe = "results/embed_{method}.csv"
    output:
        node_data = "results/embed_{method}.json"
    shell: 
        """
        python3 ../notebooks/scripts/otuput_node_data.py \
            --table {input.dataframe} \
            --output {output.node_data}
        """

rule rename_columns:
    message: "renaming columns for the concat so it can be exported to aupice (concat and ha colorbys)"
    input:
        clades = "results/embed_{method}_ma_concatenated.json",
        embedding = "results/embed_{method}_ma_concatenated.csv"
    output:
        node_data = "results/embed_{method}_ma_concatenated_renamed.json"
    params:
        rename_column = "{method}_label_ha_na_ma",
        differentiator_column = "{method}_label"
    shell: 
        """
        python3 scripts/rename_columns.py \
            --clades {input.clades} \
            --embedding {input.embedding} \
            --differentiator-column {params.differentiator_column} \
            --rename-column {params.rename_column} \
            --output {output.node_data}
        """

def _get_embedding_columns_by_wildcards(wildcards):
    method = wildcards.method.replace("-", "")
    if method in ("mds"):
        return f"{method}1 {method}2"
    else:
        return f"{method}_x {method}_y"

def _get_embedding_path_by_wildcards(wildcards):
    method = wildcards.method
    ha_concatenated = wildcards.ha_concatenated

    if method in ("mds", "t-sne", "umap"):
        return f"results/embed_{method}_{ha_concatenated}.csv"
    else:
        return "results/distance_matrix_{ha_concatenated}.csv"

rule cluster_by_parameters_ha:
    input:
        alignment="results/aligned_ha.fasta",
        distance_matrix="results/distance_matrix_ha.csv",
        clades="results/clades_ha.json",
    output:
        table=f"results/gridsearch/ha/{METHOD_PARAMETERS.wildcard_pattern}.tsv",
    params:
        method_parameters=METHOD_PARAMETERS.instance,
    conda: "../cartography.yml"
    script:
        "../notebooks/scripts/cluster_by_parameters.py"
        
rule cluster_by_parameters_concat:
    input:
        alignment="results/aligned_concatenated.fasta",
        distance_matrix="results/distance_matrix_concatenated.csv",
        clades="results/clades_ha.json",
    output:
        table=f"results/gridsearch/concatenated/{METHOD_PARAMETERS.wildcard_pattern}.tsv",
    params:
        method_parameters=METHOD_PARAMETERS.instance,
    conda: "../cartography.yml"
    script:
        "../notebooks/scripts/cluster_by_parameters.py"

rule cluster_by_parameters_ma_concat:
    input:
        alignment="results/aligned_ma_concatenated.fasta",
        distance_matrix="results/distance_matrix_ma_concatenated.csv",
        clades="results/clades_ha.json",
    output:
        table=f"results/gridsearch/ma_concatenated/{METHOD_PARAMETERS.wildcard_pattern}.tsv",
    params:
        method_parameters=METHOD_PARAMETERS.instance,
    conda: "../cartography.yml"
    script:
        "../notebooks/scripts/cluster_by_parameters.py"

rule aggregate_clusters_by_parameters:
    input:
        tables=expand("results/gridsearch/{ha_concatenated}/{params}.tsv", ha_concatenated=HA_CONCAT, params=METHOD_PARAMETERS.instance_patterns)
    output:
        table="results/gridsearch_{ha_concatenated}.tsv"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/concatenate_tables.py \
            --tables {input.tables} \
            --output {output.table}
        """

rule output_grid_search:
    input:
        table= "results/gridsearch_{ha_concatenated}.tsv",
    output:
        mds_parameters = "results/mds_parameters_{ha_concatenated}.csv",
        tsne_parameters = "results/t-sne_parameters_{ha_concatenated}.csv",
        umap_parameters = "results/umap_parameters_{ha_concatenated}.csv",
        mcc_by_method_and_distance_threshold = "results/mcc_by_method_and_distance_threshold_{ha_concatenated}.pdf"
    conda: "../cartography.yml"
    notebook:
        "../notebooks/2021-06-23-summarize-grid-search.ipynb"

rule create_notebook_docs:
    message: "creating linked and grouped charts using the jupyter notebook"
    input:
        #Charts, tree:
        node_df_ha = "results/table_ha.tsv",

        mds_df_ha = "results/embed_mds_ha.csv",
        mds_df_concatenated = "results/embed_mds_concatenated.csv",
        mds_df_ma_concatenated = "results/embed_mds_ma_concatenated.csv",

        tsne_df_ha = "results/embed_t-sne_ha.csv",
        tsne_df_concatenated = "results/embed_t-sne_concatenated.csv",
        tsne_df_ma_concatenated = "results/embed_t-sne_ma_concatenated.csv",

        umap_df_ha = "results/embed_umap_ha.csv",
        umap_df_concatenated = "results/embed_umap_concatenated.csv",
        umap_df_ma_concatenated = "results/embed_umap_ma_concatenated.csv",

    output:
        HANAMAFullChartBrushableMDSHTML = "../docs/HANAMAFullChartBrushableMDS.html",
        HANAMAFullChartBrushableMDSPNG = "../docs/HANAMAFullChartBrushableMDS.png",
        HANAMAFullChartBrushableTSNEHTML = "../docs/HANAMAFullChartBrushableTSNE.html",
        HANAMAFullChartBrushableTSNEPNG = "../docs/HANAMAFullChartBrushableTSNE.png"

    conda: "../cartography.yml"
    notebook:
        "2021-8-8NotebookFluHaNaMa.ipynb"


rule clean:
    message: "Removing directories: {params}"
    params:
        "results ",
        "auspice"
    conda: "../cartography.yml"
    shell:
        "rm -rfv {params}"
