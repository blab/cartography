EMBEDDING_METHODS = [
    "pca",
    "mds",
    "t-sne",
    "umap"
]

KDE_METHODS = [
    "pca",
    "mds",
    "t-sne",
    "umap",
    "genetic"
]

SEGMENTS = [
    "ha",
    "na"
]

HA_CONCATENATED = [
    "concatenated",
    "ha"
]

#TO DO: add HA only embeddings and HA+NA embeddings

rule all:
    input:
        "results/ncbi-h3n2-ha.fasta",
        expand("results/scatterplot_{method}_{ha_concatenated}.png", method=EMBEDDING_METHODS, ha_concatenated=HA_CONCATENATED),
        expand("results/KDEDensity_{method}_{ha_concatenated}.png", method=KDE_METHODS, ha_concatenated=HA_CONCATENATED),
        expand("results/aligned_{segment}.fasta", segment=SEGMENTS),
        expand("results/deduplicated_sequences_{segment}.fasta", segment=SEGMENTS),
        expand("results/filtered_{segment}.fasta", segment=SEGMENTS),
        expand("results/metadata_{segment}.tsv", segment=SEGMENTS),
        "results/aligned_concatenated.fasta",
        #"../auspice/cartography_flu-seasonal-h3n2-ha-na-2016-2018.json",
        "results/table.tsv",
        expand("results/full_KDE_metadata_{ha_concatenated}.csv", ha_concatenated=HA_CONCATENATED),
        expand("results/full_Scatterplot_metadata_{ha_concatenated}.csv", ha_concatenated=HA_CONCATENATED),
        expand("results/embed_pca_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED),
        expand("results/embed_mds_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED),
        expand("results/embed_t-sne_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED),
        expand("results/embed_umap_{ha_concatenated}.json", ha_concatenated=HA_CONCATENATED)
        #"results/explained_variance_pca.csv",
        #"../docs/FullKDEDensityFluHaNa.png",
        #"../docs/FullScatterplotFluHaNa.png",
        #"../docs/FullLinkedChartBrushableFluHaNa.html",
        #"../docs/flu-embeddings.png",
        #"../docs/FullMDSBrushSupplementFluHaNa.html",
        #"../docs/FullPCABrushSupplementFluHaNa.html",
        #"results/nucleotide_diversity.txt",
        #"../docs/explainedVarianceFluHaNa.png"

rule files:
    params:
        input_fasta = "data/ncbi-h3n2-ha-na.fa",
        dropped_strains = "config/exclude.txt",
        reference = "config/reference_h3n2_ha.gb",
        auspice_config = "config/auspice_config.json",
        clades = "config/clades_h3n2_ha.tsv"

files = rules.files.params

rule split:
    message:
        """
        Split the ha and na file into separate files
        """
    input:
        sequences =  "data/ncbi-h3n2-ha-na.fa",
    output:
        sequences_ha = "results/ncbi-h3n2-ha.fasta",
        sequences_na = "results/ncbi-h3n2-na.fasta"
    conda: "../cartography/yml"
    shell:
        """
        python3 scripts/split_fasta.py \
            --sequence {input.sequences} \
            --output_fastas {output.sequences_ha} {output.sequences_na}\
        """

rule parse:
    message: "Parsing fasta into sequences and metadata"
    input:
        sequences = "results/ncbi-h3n2-{segment}.fasta"
    output:
        sequences = "results/sequences_{segment}.fasta",
        metadata = "results/metadata_{segment}.tsv"
    params:
        fasta_fields = "strain date accession country region segment_name"
    conda: "../cartography.yml"
    shell:
        """
        augur parse \
            --sequences {input.sequences} \
            --output-sequences {output.sequences} \
            --output-metadata {output.metadata} \
            --fields {params.fasta_fields}
        """

rule deduplicate_sequences:
    message:
        """
        Deduplicating sequences
        """
    input:
        sequences = rules.parse.output.sequences
    output:
        sequences = "results/deduplicated_sequences_{segment}.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/deduplicate_sequences.py \
            --sequences {input.sequences} \
            --output {output.sequences}
        """

rule filter:
    message:
        """
        Filtering to
          - {params.sequences_per_group} sequence(s) per {params.group_by!s}
          - from {params.min_date} onwards
          - excluding strains in {input.exclude}
        """
    input:
        sequences = "results/deduplicated_sequences_{segment}.fasta",
        metadata = "results/metadata_{segment}.tsv",
        exclude = files.dropped_strains
    output:
        sequences = "results/filtered_{segment}.fasta"
    params:
        group_by = "country year month",
        sequences_per_group = 10,
        min_date = 1900,
        max_date = 2050
    conda: "../cartography.yml"
    shell:
        """
        augur filter \
            --sequences {input.sequences} \
            --metadata {input.metadata} \
            --exclude {input.exclude} \
            --output {output.sequences} \
            --group-by {params.group_by} \
            --sequences-per-group {params.sequences_per_group} \
            --min-date {params.min_date} \
            --max-date {params.max_date}
        """

rule align:
    message:
        """
        Aligning sequences to {input.reference}
          - filling gaps with N
        """
    input:
        sequences = rules.filter.output.sequences,
        reference = files.reference
    output:
        alignment = "results/aligned_{segment}.fasta"
    conda: "../cartography.yml"
    threads: 4
    shell:
        """
        augur align \
            --sequences {input.sequences} \
            --reference-sequence {input.reference} \
            --output {output.alignment} \
            --fill-gaps \
            --remove-reference \
            --nthreads {threads}
        """

rule concat:
    message: 
        """putting the na strains with the ha strains"""
    input:
        sequence_ha = "results/aligned_ha.fasta",
        sequence_na = "results/aligned_na.fasta"
    output:
        fasta = "results/aligned_concatenated.fasta"
    conda: "../cartography.yml"
    shell:
        """
        python3 scripts/concat_sequences.py \
            --sequences {input.sequence_ha} {input.sequence_na}\
            --output {output.fasta} \
        """


rule tree:
    message: "Building tree"
    input:
        alignment = "results/aligned_ha.fasta"
    output:
        tree = "results/tree_raw.nwk"
    conda: "../cartography.yml"
    threads: 4
    shell:
        """
        augur tree \
            --alignment {input.alignment} \
            --output {output.tree} \
            --nthreads {threads}
        """

rule refine:
    message:
        """
        Refining tree
          - estimate timetree
          - use {params.coalescent} coalescent timescale
          - estimate {params.date_inference} node dates
          - filter tips more than {params.clock_filter_iqd} IQDs from clock expectation
        """
    input:
        tree = rules.tree.output.tree,
        alignment = "results/aligned_ha.fasta",
        metadata = "results/metadata_ha.tsv",
    output:
        tree = "results/tree.nwk",
        node_data = "results/branch_lengths.json"
    params:
        coalescent = "opt",
        date_inference = "marginal",
        clock_filter_iqd = 4,
        clock_rate = 0.00382,
        clock_std_dev = 0.000764
    conda: "../cartography.yml"
    shell:
        """
        augur refine \
            --tree {input.tree} \
            --alignment {input.alignment} \
            --metadata {input.metadata} \
            --output-tree {output.tree} \
            --output-node-data {output.node_data} \
            --timetree \
            --coalescent {params.coalescent} \
            --date-confidence \
            --date-inference {params.date_inference} \
            --clock-filter-iqd {params.clock_filter_iqd} \
            --clock-rate {params.clock_rate} \
            --clock-std-dev {params.clock_std_dev}
        """

rule ancestral:
    message: "Reconstructing ancestral sequences and mutations"
    input:
        tree = rules.refine.output.tree,
        alignment = "results/aligned_ha.fasta"
    output:
        node_data = "results/nt_muts.json"
    params:
        inference = "joint"
    conda: "../cartography.yml"
    shell:
        """
        augur ancestral \
            --tree {input.tree} \
            --alignment {input.alignment} \
            --output-node-data {output.node_data} \
            --inference {params.inference}
        """

rule translate:
    message: "Translating amino acid sequences"
    input:
        tree = rules.refine.output.tree,
        node_data = rules.ancestral.output.node_data,
        reference = files.reference
    output:
        node_data = "results/aa_muts.json"
    conda: "../cartography.yml"
    shell:
        """
        augur translate \
            --tree {input.tree} \
            --ancestral-sequences {input.node_data} \
            --reference-sequence {input.reference} \
            --output {output.node_data} 
        """

rule clades:
    message: " Labeling clades as specified in config/clades.tsv"
    input:
        tree = rules.refine.output.tree,
        aa_muts = rules.translate.output.node_data,
        nuc_muts = rules.ancestral.output.node_data,
        clades = files.clades
    output:
        clade_data = "results/clades.json"
    conda: "../cartography.yml"
    shell:
        """
        augur clades --tree {input.tree} \
            --mutations {input.nuc_muts} {input.aa_muts} \
            --clades {input.clades} \
            --output {output.clade_data}
        """

rule traits:
    message: "Inferring ancestral traits for {params.columns!s}"
    input:
        tree = rules.refine.output.tree,
        metadata = "results/metadata_ha.tsv",
    output:
        node_data = "results/traits.json",
    params:
        columns = "region country"
    conda: "../cartography.yml"
    shell:
        """
        augur traits \
            --tree {input.tree} \
            --metadata {input.metadata} \
            --output {output.node_data} \
            --columns {params.columns} \
            --confidence
        """

rule export:
    message: "Exporting data files for for auspice"
    input:
        tree = rules.refine.output.tree,
        metadata = "results/metadata_ha.tsv",
        branch_lengths = rules.refine.output.node_data,
        traits = rules.traits.output.node_data,
        nt_muts = rules.ancestral.output.node_data,
        aa_muts = rules.translate.output.node_data,
        embeddings = expand("results/embed_{embedding}_ha.json", embedding=EMBEDDING_METHODS),
        auspice_config = files.auspice_config,
        colors = "config/colors.tsv",
        clades = rules.clades.output.clade_data
    output:
        auspice_tree = "../auspice/cartography_flu-seasonal-h3n2-ha-2016-2018.json"
    conda: "../cartography.yml"
    shell:
        """
        augur export v2 \
            --tree {input.tree} \
            --metadata {input.metadata} \
            --node-data {input.branch_lengths} {input.traits} {input.clades} {input.nt_muts} {input.aa_muts} {input.embeddings} \
            --auspice-config {input.auspice_config} \
            --colors {input.colors} \
            --output {output.auspice_tree}
        """

rule tree_to_table:
    message: "creating a table of node data values from the tree attributes"
    input: 
        tree = rules.export.output.auspice_tree
    output:
        table = "results/table.tsv"
    params:
        attributes = "num_date pca1 pca2 pca3 pca4 mds1 mds2 mds3 mds4 tsne_x tsne_y umap_x umap_y clade_membership pca_label mds_label umap_label t-sne_label"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/auspice_tree_to_table.py \
            {input.tree} \
            {output.table} \
            --attributes {params.attributes}
        """

rule create_distance_matrix:
    message: "creating the distance matrix to be used in the rest of the analysis"
    input:
        alignment = "results/aligned_{ha_concatenated}.fasta"
    output:
        output = "results/distance_matrix_{ha_concatenated}.csv"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/hamming_distance_from_fasta.py \
            --alignment {input.alignment} \
            --output {output.output}
        """

rule embed_pca:
    message: "Creating the embedding (dataframe, node JSON) for PCA"
    input:
        alignment = "results/aligned_{ha_concatenated}.fasta"
    output:
        node_data = "results/embed_pca_{ha_concatenated}.json",
        dataframe = "results/embed_pca_{ha_concatenated}.csv",
        figure = "results/embed_pca_{ha_concatenated}.pdf",
        explained_variance = "results/explained_variance_pca_{ha_concatenated}.csv"
    params:
        components = 10
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/embed.py \
            --alignment {input.alignment} \
            --cluster \
            --random-seed 314159 \
            --output-node-data {output.node_data} \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            pca \
            --components {params.components} \
            --explained-variance {output.explained_variance}
        """


rule embed_tsne:
    message: "Creating the embedding (dataframe, node JSON) for t-SNE"
    input:
        distance_matrix = rules.create_distance_matrix.output.output
    output:
        node_data = "results/embed_t-sne_{ha_concatenated}.json",
        dataframe = "results/embed_t-sne_{ha_concatenated}.csv",
        figure = "results/embed_t-sne_{ha_concatenated}.pdf"
    params:
        perplexity = 25.95,
        learning_rate = 200
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/embed.py \
            --distance-matrix {input.distance_matrix} \
            --cluster \
            --random-seed 314159 \
            --output-node-data {output.node_data} \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            t-sne \
            --perplexity {params.perplexity} \
            --learning-rate {params.learning_rate}
        """

rule embed_umap:
    message: "Creating the embedding (dataframe, node JSON) for UMAP"
    input:
        distance_matrix = rules.create_distance_matrix.output.output
    output:
        node_data = "results/embed_umap_{ha_concatenated}.json",
        dataframe = "results/embed_umap_{ha_concatenated}.csv",
        figure = "results/embed_umap_{ha_concatenated}.pdf"
    params:
        nearest_neighbors = 200,
        min_dist = .5
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/embed.py \
            --distance-matrix {input.distance_matrix} \
            --cluster \
            --random-seed 314159 \
            --output-node-data {output.node_data} \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            umap \
            --nearest-neighbors {params.nearest_neighbors} \
            --min-dist {params.min_dist}
        """

rule embed_mds:
    message: "Creating the embedding (dataframe, node JSON) for MDS"
    input:
        distance_matrix = rules.create_distance_matrix.output.output
    output:
        node_data = "results/embed_mds_{ha_concatenated}.json",
        dataframe = "results/embed_mds_{ha_concatenated}.csv",
        figure = "results/embed_mds_{ha_concatenated}.pdf"
    params:
        components = 10
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/embed.py \
            --distance-matrix {input.distance_matrix} \
            --cluster \
            --random-seed 314159 \
            --output-node-data {output.node_data} \
            --output-dataframe {output.dataframe} \
            --output-figure {output.figure} \
            mds \
            --components {params.components} \
        """

def _get_embedding_columns_by_wildcards(wildcards):
    method = wildcards.method.replace("-", "")

    if method in ("pca", "mds"):
        return f"{method}1 {method}2 {method}3 {method}4"
    else:
        return f"{method}_x {method}_y"


rule scatterplot:
    message: "Creating the scatterplot (PNG, dataframe)"
    input:
        distance_matrix = "results/distance_matrix_{ha_concatenated}.csv",
        embedding = "results/embed_{method}_{ha_concatenated}.csv",
    output:
        figure = "results/scatterplot_{method}_{ha_concatenated}.png",
        dataframe = "results/scatterplot_{method}_{ha_concatenated}.csv",
        metadata = "results/scatterplot_{method}_metadata_{ha_concatenated}.csv"
    params:
        bootstrap = 1000,
        nucleotides = 1701.0,
        columns = _get_embedding_columns_by_wildcards
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/scatterplot.py \
            --distance {input.distance_matrix} \
            --embedding {input.embedding} \
            --method {wildcards.method} \
            --columns {params.columns} \
            --bootstrapping-sample {params.bootstrap} \
            --output-figure {output.figure} \
            --output-dataframe {output.dataframe} \
            --output-metadata {output.metadata} \
            --nucleotide {params.nucleotides}
        """

def _get_embedding_path_by_wildcards(wildcards):
    method = wildcards.method
    ha_concatenated = wildcards.ha_concatenated

    if method in ("pca", "mds", "t-sne", "umap"):
        return f"results/embed_{method}_{ha_concatenated}.csv"
    else:
        return "results/distance_matrix_{ha_concatenated}.csv"

rule KDE_density:
    message: "creating the KDE density plot"
    input:
        embedding = _get_embedding_path_by_wildcards,
        clades = "results/clades.json",
    output:
        figure = "results/KDEDensity_{method}_{ha_concatenated}.png",
        dataframe = "results/KDEDensity_{method}_{ha_concatenated}.csv",
        metadata = "results/KDEDensity_{method}_metadata_{ha_concatenated}.csv"
    params:
        embedding_columns = _get_embedding_columns_by_wildcards,
        differentiator_column = "clade_membership"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/within_vs_between_status.py \
            --embedding {input.embedding} \
            --clades {input.clades} \
            --method {wildcards.method} \
            --embedding-columns {params.embedding_columns} \
            --differentiator-column {params.differentiator_column} \
            --output-figure {output.figure} \
            --output-dataframe {output.dataframe} \
            --output-metadata {output.metadata}
        """

rule concat_KDE_table:
    message: "concatenating all the KDE data into one csv dataframe"
    input:
       dataframe_pca = "results/KDEDensity_pca_metadata_{ha_concatenated}.csv",
       dataframe_mds = "results/KDEDensity_mds_metadata_{ha_concatenated}.csv", 
       dataframe_tsne = "results/KDEDensity_t-sne_metadata_{ha_concatenated}.csv", 
       dataframe_umap = "results/KDEDensity_umap_metadata_{ha_concatenated}.csv",
       dataframe_genetic = "results/KDEDensity_genetic_metadata_{ha_concatenated}.csv"
    output:
        metadata = "results/full_KDE_metadata_{ha_concatenated}.csv"
    params:
        column = "MCC",
        dataframes = "results/KDEDensity_pca_metadata_{ha_concatenated}.csv results/KDEDensity_mds_metadata_{ha_concatenated}.csv results/KDEDensity_t-sne_metadata_{ha_concatenated}.csv results/KDEDensity_umap_metadata_{ha_concatenated}.csv results/KDEDensity_genetic_metadata_{ha_concatenated}.csv"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/concatenate_tables.py \
            --tables {params.dataframes} \
            --separator ',' \
            --sort-by {params.column} \
            --output {output.metadata}
        """

rule concat_scatterplot_table:
    message: "concatenating all the scatterplot metadata into one csv dataframe"
    input:
       dataframe_pca = "results/scatterplot_pca_metadata_{ha_concatenated}.csv",
       dataframe_mds = "results/scatterplot_mds_metadata_{ha_concatenated}.csv", 
       dataframe_tsne = "results/scatterplot_t-sne_metadata_{ha_concatenated}.csv", 
       dataframe_umap = "results/scatterplot_umap_metadata_{ha_concatenated}.csv"
    output:
        metadata = "results/full_Scatterplot_metadata_{ha_concatenated}.csv"
    params:
        column = "pearson_coef",
        dataframes = "results/scatterplot_pca_metadata_{ha_concatenated}.csv results/scatterplot_mds_metadata_{ha_concatenated}.csv results/scatterplot_t-sne_metadata_{ha_concatenated}.csv results/scatterplot_umap_metadata_{ha_concatenated}.csv"
    conda: "../cartography.yml"
    shell:
        """
        python3 ../notebooks/scripts/concatenate_tables.py \
            --tables {params.dataframes} \
            --separator ',' \
            --sort-by {params.column} \
            --output {output.metadata}
        """

rule create_notebook_docs:
    message: "creating linked and grouped charts using the jupyter notebook"
    input:
        #Charts, tree:
        node_df = "results/table.tsv",

        pca_df = "results/embed_pca.csv",
        explained_variance_pca = "results/explained_variance_pca.csv",

        mds_df = "results/embed_mds.csv",

        #Scatterplot:
        scatterplot_pca = "results/scatterplot_pca.csv",
        scatterplot_pca_metadata = "results/scatterplot_pca_metadata.csv",

        scatterplot_mds = "results/scatterplot_mds.csv",
        scatterplot_mds_metadata = "results/scatterplot_mds_metadata.csv",

        scatterplot_tsne = "results/scatterplot_t-sne.csv",
        scatterplot_tsne_metadata = "results/scatterplot_t-sne_metadata.csv",

        scatterplot_umap = "results/scatterplot_umap.csv",
        scatterplot_umap_metadata = "results/scatterplot_umap_metadata.csv",

        #KDE Density:
        KDE_pca = "results/KDEDensity_pca.csv",
        KDE_pca_metadata = "results/KDEDensity_pca_metadata.csv",

        KDE_mds = "results/KDEDensity_mds.csv",
        KDE_mds_metadata = "results/KDEDensity_mds_metadata.csv",

        KDE_tsne = "results/KDEDensity_t-sne.csv",
        KDE_tsne_metadata = "results/KDEDensity_t-sne_metadata.csv",

        KDE_umap = "results/KDEDensity_umap.csv",
        KDE_umap_metadata = "results/KDEDensity_umap_metadata.csv",

        KDE_genetic = "results/KDEDensity_genetic.csv",
        KDE_genetic_metadata = "results/KDEDensity_genetic_metadata.csv",

    output:
        KDE_density = "../docs/FullKDEDensityFluHaNa.png",
        Scatterplot = "../docs/FullScatterplotFluHaNa.png",
        fullChart = "../docs/FullLinkedChartBrushableFluHaNa.html",
        fullChartPNG = "../docs/flu-embeddingsHaNa.png",
        MDS_Supplement = "../docs/FullMDSBrushSupplementFluHaNa.html",
        MDS_Supplement_PNG = "../docs/FullMDSBrushSupplementFluHaNa.png",
        PCA_Supplement = "../docs/FullPCABrushSupplementFluHaNa.html",
        PCA_Supplement_PNG = "../docs/FullPCABrushSupplementFluHaNa.png",
        Explained_variance_PCA = "../docs/explainedVarianceFluHaNa.png"

    conda: "../cartography.yml"
    notebook:
        "2020-12-21NotebookFluHaNa.ipynb"

rule clean:
    message: "Removing directories: {params}"
    params:
        "results ",
        "auspice"
    conda: "../cartography.yml"
    shell:
        "rm -rfv {params}"
